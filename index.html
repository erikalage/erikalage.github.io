<!DOCTYPE html>
<html>

<head>
    <title>Isaac Lage</title>

    <link type="text/css" rel="stylesheet" href="css/main.css" />
</head>

<body>

    <div id="name">
        <h1>Isaac Lage</h1>
        <p><b>Email:</b> isaaclage AT g.harvard.edu</p>
        <p><b>Pronouns:</b> he/him/his</p>
    </div>

    <hr>

    <div id="body">
        <div id="photo">
            <img src="images/photo.jpg", id="photo">
        </div>

        <div id="research_interests">

            <p id="affiliations">
                I am Ph.D. student in Computer Science at Harvard (started fall 2017) working with <a href="https://finale.seas.harvard.edu/">Professor Finale Doshi-Velez</a> in the Data to Actionable Knowledge (DtAK) lab.  I work on techniques to learn interpretable models by incorporating user studies into existing optimization methods.
            </p>

            <p id="affiliations">
                I was previously a Research Software Engineer working with <a href="http://cs.nyu.edu/~dsontag/">Professor David Sontag</a> in the <a href="http://clinicalml.org/">Clinical Machine Learning Group</a> at MIT.  I worked on predicting hospital readmissions and modeling the disease progression of multiple myeloma.
            </p>

            <p id="affiliations">
                I earned a B.A. in Computer Science and Social & Cultural Analysis from NYU in 2016.
            </p>

            <p id="interests">
                <b>Publications:</b>
                <ul>
                    <li>Lage I, Lifschitz D, Doshi-Velez F, Amir O. Toward Robust Policy Summarization - Extended Abstract. International Conference on Autonomous Agents and Multiagent Systems (AAMAS). 2019.</li>

                    <li>Lage I, Ross A, Kim B, Gershman S, Doshi-Velez F. <a href="http://papers.nips.cc/paper/8219-human-in-the-loop-interpretability-prior">Human-in-the-Loop Interpretability Prior.</a> Conference on Neural Information Processing Systems (NeurIPS). 2018.</li>

                    <li>Lage I, Chen E, He J, Narayanan M, Gershman S, Kim B, Doshi-Velez F. <a href="https://www.dropbox.com/s/5knzhdpvwkqon65/CRACT_2018_paper_8.pdf?dl=0">An Evaluation of the Human-Interpretability of Explanation</a>. Conference on Neural Information Processing Systems (NeurIPS) Workshop on Correcting and Critiquing Trends in Machine Learning. 2018. <a href="https://arxiv.org/abs/1902.00006">Extended version.</a></li>

                    <li>Ross AS, Lage I, Doshi-Velez F. (2017). <a href="https://goo.gl/TwRhXo">The Neural Lasso: Local Linear Sparsity for Interpretable Explanations</a></li>
                </ul>                        
            </p>
         </div>
    </div>

</body>
</html>
